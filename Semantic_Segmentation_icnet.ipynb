{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":486,"status":"ok","timestamp":1698443153392,"user":{"displayName":"Amarnath Shinde","userId":"15881715752542230515"},"user_tz":240},"id":"HcwRYzV_yGVD","pycharm":{"is_executing":false}},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from models import ICNet\n","import torch\n","import numpy as np\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["dict_keys(['cur_epoch', 'best_score', 'state_dict', 'optimizer', 'scheduler'])\n"]},{"data":{"text/plain":["ICNet(\n","  (backbone): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (bottom_branch): HighResolutionBranch(\n","    (0): ConvBNAct(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","    (1): ConvBNAct(\n","      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","    (2): ConvBNAct(\n","      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","  )\n","  (ppm): PyramidPoolingModule(\n","    (stage1): Sequential(\n","      (0): AdaptiveAvgPool2d(output_size=1)\n","      (1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (stage2): Sequential(\n","      (0): AdaptiveAvgPool2d(output_size=2)\n","      (1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (stage3): Sequential(\n","      (0): AdaptiveAvgPool2d(output_size=4)\n","      (1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (stage4): Sequential(\n","      (0): AdaptiveAvgPool2d(output_size=6)\n","      (1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (conv): ConvBNAct(\n","      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","  )\n","  (cff42): CascadeFeatureFusionUnit(\n","    (conv1): ConvBNAct(\n","      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): Identity()\n","      )\n","    )\n","    (conv2): ConvBNAct(\n","      (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): Identity()\n","      )\n","    )\n","    (act): Activation(\n","      (activation): ReLU()\n","    )\n","    (classifier): SegHead(\n","      (0): ConvBNAct(\n","        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (cff21): CascadeFeatureFusionUnit(\n","    (conv1): ConvBNAct(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): Identity()\n","      )\n","    )\n","    (conv2): ConvBNAct(\n","      (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): Identity()\n","      )\n","    )\n","    (act): Activation(\n","      (activation): ReLU()\n","    )\n","    (classifier): SegHead(\n","      (0): ConvBNAct(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (seg_head): SegHead(\n","    (0): ConvBNAct(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","    (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","  )\n",")"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Define the ICNet model with the same configuration as during training\n","net = ICNet(num_class=19, n_channel=3, backbone_type='resnet18', act_type='relu', use_aux=True)\n","\n","# Load the checkpoint\n","checkpoint_path = 'C:/Users/avshinde/Downloads/New folder/New folder/icnet.pth'  # Replace with the actual path to your checkpoint file\n","checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # Add map_location argument if needed\n","print(checkpoint.keys())\n","\n","# Load the model state_dict\n","net.load_state_dict(checkpoint['state_dict'])\n","\n","net=net.to(device)\n","\n","# Ensure the model is in evaluation mode\n","net.eval()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Parameters: 12881215\n","Non-Zero Parameters: 12881215\n","Zero Parameters: 0\n"]}],"source":["total_params = 0\n","non_zero_params = 0\n","zero_params = 0\n","\n","for name, param in net.state_dict().items():\n","        total_params += param.numel()\n","        non_zero_params += torch.count_nonzero(param).item()\n","        zero_params += (param.numel() - torch.count_nonzero(param)).item()\n","print(f\"Total Parameters: {total_params}\")\n","print(f\"Non-Zero Parameters: {non_zero_params}\")\n","print(f\"Zero Parameters: {zero_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"00k3oTlVyGVF"},"source":["### Prune"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5215,"status":"ok","timestamp":1698443199199,"user":{"displayName":"Amarnath Shinde","userId":"15881715752542230515"},"user_tz":240},"id":"4pdiSJHZyGVF","outputId":"7ece561c-5eb2-452a-bcb5-e89a589ef625"},"outputs":[],"source":["from prune import prune_icnet\n","prune_icnet(net, method='std', s=0.25)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# If needed, remove pruning\n","from torch.nn.utils import prune\n","\n","for name, module in net.named_modules():\n","    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n","        prune.remove(module, 'weight')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Parameters: 12881215\n","Non-Zero Parameters: 9666239\n","Zero Parameters: 3214976\n"]}],"source":["total_params = 0\n","non_zero_params = 0\n","zero_params = 0\n","\n","for name, param in net.state_dict().items():\n","        total_params += param.numel()\n","        non_zero_params += torch.count_nonzero(param).item()\n","        zero_params += (param.numel() - torch.count_nonzero(param)).item()\n","print(f\"Total Parameters: {total_params}\")\n","print(f\"Non-Zero Parameters: {non_zero_params}\")\n","print(f\"Zero Parameters: {zero_params}\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# # Print the names and values of the parameters\n","# for name, param in net.named_parameters():\n","#     print(f'Parameter name: {name}')\n","#     print(f'Parameter shape: {param.shape}')\n","#     print(f'Parameter data:\\n{param.data}\\n')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Create a new model to store the pruned weights\n","pruned_model = ICNet(num_class=19, n_channel=3, backbone_type='resnet18', act_type='relu', use_aux=True)\n","pruned_model.load_state_dict(net.state_dict())"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Save the updated checkpoint\n","updated_checkpoint_path = 'updated_checkpoint_icnet.pth'\n","checkpoint['state_dict'] = pruned_model.state_dict()\n","checkpoint['cur_epoch'] = 0\n","checkpoint['best_score'] = 0\n","torch.save(checkpoint, updated_checkpoint_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Fine-tuning pruned weights and prediction"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Original mIoU: 69.65\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Obtained mIoU: 66.18"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","[2023-12-04 11:32] Load model state dict from C:/Users/avshinde/Downloads/New folder/New folder/updated_checkpoint_icnet.pth\n","[2023-12-04 11:32] Resume training from C:/Users/avshinde/Downloads/New folder/New folder/updated_checkpoint_icnet.pth\n","[2023-12-04 11:32] \n","\n","\n","######################### Config Informations #########################\n","dataset: cityscapes\n","num_class: 19\n","model: icnet\n","encoder: None\n","decoder: None\n","loss_type: ohem\n","optimizer_type: adam\n","lr_policy: cos_warmup\n","total_epoch: 10\n","train_bs: 8\n","val_bs: 8\n","train_num: 2968\n","val_num: 500\n","gpu_num: 1\n","num_workers: 8\n","amp_training: False\n","DDP: False\n","kd_training: False\n","synBN: True\n","use_ema: True\n","use_aux: True\n","#######################################################################\n","\n","\n","Epoch:1/10    |Loss:2.743    |: 100%|██████████| 371/371 [05:26<00:00,  1.14it/s]\n","Validating:    |: 100%|██████████| 63/63 [02:17<00:00,  2.18s/it] \n","[2023-12-04 11:39]  Epoch1 mIoU: 0.4977    | best mIoU so far: 0.0000\n","\n"]},{"name":"stdout","output_type":"stream","text":["tensor(0.4977, device='cuda:0')\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:2/10    |Loss:2.885    |: 100%|██████████| 371/371 [05:30<00:00,  1.12it/s]\n","Validating:    |: 100%|██████████| 63/63 [02:18<00:00,  2.19s/it] \n","[2023-12-04 11:47]  Epoch2 mIoU: 0.5912    | best mIoU so far: 0.4977\n","\n"]},{"name":"stdout","output_type":"stream","text":["tensor(0.5912, device='cuda:0')\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:3/10    |Loss:4.653    |: 100%|██████████| 371/371 [05:32<00:00,  1.11it/s]\n","Validating:    |: 100%|██████████| 63/63 [02:15<00:00,  2.15s/it] \n","[2023-12-04 11:55]  Epoch3 mIoU: 0.6196    | best mIoU so far: 0.5912\n","\n"]},{"name":"stdout","output_type":"stream","text":["tensor(0.6196, device='cuda:0')\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:4/10    |Loss:2.841    |: 100%|██████████| 371/371 [05:35<00:00,  1.11it/s]\n","Validating:    |: 100%|██████████| 63/63 [02:14<00:00,  2.14s/it] \n","[2023-12-04 12:03]  Epoch4 mIoU: 0.6266    | best mIoU so far: 0.6196\n","\n"]},{"name":"stdout","output_type":"stream","text":["tensor(0.6266, device='cuda:0')\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:5/10    |Loss:3.074    |: 100%|██████████| 371/371 [05:30<00:00,  1.12it/s]\n","Validating:    |: 100%|██████████| 63/63 [02:26<00:00,  2.32s/it] \n","[2023-12-04 12:11]  Epoch5 mIoU: 0.6367    | best mIoU so far: 0.6266\n","\n"]},{"name":"stdout","output_type":"stream","text":["tensor(0.6367, device='cuda:0')\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:6/10    |Loss:2.368    |: 100%|██████████| 371/371 [05:34<00:00,  1.11it/s]\n","Validating:    |: 100%|██████████| 63/63 [02:15<00:00,  2.15s/it] \n","[2023-12-04 12:19]  Epoch6 mIoU: 0.6462    | best mIoU so far: 0.6367\n","\n"]},{"name":"stdout","output_type":"stream","text":["tensor(0.6462, device='cuda:0')\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:7/10    |Loss:3.123    |: 100%|██████████| 371/371 [05:34<00:00,  1.11it/s]\n","Validating:    |: 100%|██████████| 63/63 [02:18<00:00,  2.20s/it] \n","[2023-12-04 12:27]  Epoch7 mIoU: 0.6532    | best mIoU so far: 0.6462\n","\n"]},{"name":"stdout","output_type":"stream","text":["tensor(0.6532, device='cuda:0')\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/371 [00:14<?, ?it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m     trainer\u001b[39m.\u001b[39mpredict(config)\n\u001b[0;32m     21\u001b[0m \u001b[39melse\u001b[39;00m:    \n\u001b[1;32m---> 22\u001b[0m     trainer\u001b[39m.\u001b[39;49mrun(config)\n","File \u001b[1;32mc:\\Users\\avshinde\\Downloads\\New folder\\New folder\\core\\base_trainer.py:85\u001b[0m, in \u001b[0;36mBaseTrainer.run\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mfor\u001b[39;00m cur_epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_epoch, config\u001b[39m.\u001b[39mtotal_epoch):\n\u001b[0;32m     83\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_epoch \u001b[39m=\u001b[39m cur_epoch\n\u001b[1;32m---> 85\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_one_epoch(config)\n\u001b[0;32m     87\u001b[0m     \u001b[39mif\u001b[39;00m cur_epoch \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mbegin_val_epoch \u001b[39mand\u001b[39;00m cur_epoch \u001b[39m%\u001b[39m config\u001b[39m.\u001b[39mval_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     88\u001b[0m         val_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate(config)\n","File \u001b[1;32mc:\\Users\\avshinde\\Downloads\\New folder\\New folder\\core\\seg_trainer.py:31\u001b[0m, in \u001b[0;36mSegTrainer.train_one_epoch\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m sampler_set_epoch(config, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_epoch) \n\u001b[0;32m     29\u001b[0m pbar \u001b[39m=\u001b[39m tqdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmain_rank \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader\n\u001b[1;32m---> 31\u001b[0m \u001b[39mfor\u001b[39;00m cur_itrs, (images, masks) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pbar):\n\u001b[0;32m     32\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_itrs \u001b[39m=\u001b[39m cur_itrs\n\u001b[0;32m     33\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_itrs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1040\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n","File \u001b[1;32mc:\\Program Files\\Python310\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n","File \u001b[1;32mc:\\Program Files\\Python310\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n","File \u001b[1;32mc:\\Program Files\\Python310\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n","File \u001b[1;32mc:\\Program Files\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n","File \u001b[1;32mc:\\Program Files\\Python310\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from core import SegTrainer\n","from configs import MyConfig, load_parser\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","if __name__ == '__main__':\n","    config = MyConfig()\n","    \n","    config.init_dependent_config()\n","\n","    #config.model = net\n","    # If you want to use command-line arguments, please uncomment the following line\n","    # config = load_parser(config)\n","\n","    trainer = SegTrainer(config)\n","    \n","    if config.is_testing:\n","        trainer.predict(config)\n","    else:    \n","        trainer.run(config)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Predicting on the fine-tuned weights"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[2023-12-04 12:33] Load model state dict from C:/Users/avshinde/Downloads/New folder/New folder/save/last.pth\n","[2023-12-04 12:33] \n","Start predicting...\n","\n","100%|██████████| 38/38 [09:22<00:00, 14.81s/it]\n"]}],"source":["from core import SegTrainer\n","from configs import MyConfig, load_parser\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","if __name__ == '__main__':\n","    config = MyConfig()\n","    \n","    config.init_dependent_config()\n","\n","    #config.model = net\n","    # If you want to use command-line arguments, please uncomment the following line\n","    # config = load_parser(config)\n","\n","    trainer = SegTrainer(config)\n","    \n","    if config.is_testing:\n","        trainer.predict(config)\n","    else:    \n","        trainer.run(config)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Video Output"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import cv2\n","import os\n","from natsort import natsorted\n","\n","# Directory containing the predicted segmentation images\n","image_folder = 'C:/Users/avshinde/Downloads/New folder/New folder/save/mainz_finetuned/blend'\n","\n","# Output video file name\n","video_name = 'output_video_mainz_finetuned.avi'\n","\n","# Get the list of image files and sort them\n","images = [img for img in os.listdir(image_folder) if img.endswith(\"blend.png\")]\n","images = natsorted(images)\n","\n","# Get image dimensions from the first image\n","img = cv2.imread(os.path.join(image_folder, images[0]))\n","height, width, layers = img.shape\n","\n","# Define the desired frame rate (adjust as needed)\n","desired_frame_rate = 1 # Frames per second\n","\n","# Create a VideoWriter object with the desired frame rate\n","video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'XVID'), desired_frame_rate, (width, height))\n","\n","# Loop through the images and write each frame to the video\n","for image in images:\n","    img_path = os.path.join(image_folder, image)\n","    frame = cv2.imread(img_path)\n","    video.write(frame)\n","\n","# Release the VideoWriter object\n","video.release()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["GIF saved as output_video_mainz.gif\n"]}],"source":["import cv2\n","import os\n","from natsort import natsorted\n","import imageio\n","\n","# Directory containing the predicted segmentation images\n","image_folder = 'C:/Users/avshinde/Downloads/New folder/New folder/save'\n","\n","# Output GIF file name\n","gif_name = 'output_video_mainz.gif'\n","\n","# Get the list of image files and sort them\n","images = [img for img in os.listdir(image_folder) if img.endswith(\"blend.png\")]\n","images = natsorted(images)\n","\n","# Get image dimensions from the first image\n","img = cv2.imread(os.path.join(image_folder, images[0]))\n","height, width, layers = img.shape\n","\n","# Define the desired frame rate (adjust as needed)\n","desired_frame_rate = 0.7 # Frames per second\n","\n","# Create a list to store frames\n","frames = []\n","\n","# Loop through the images and append each frame to the list\n","for image in images:\n","    img_path = os.path.join(image_folder, image)\n","    frame = cv2.imread(img_path)\n","    # Ensure that the color channels are in the correct order (BGR)\n","    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    frames.append(frame)\n","\n","# Save the frames as a GIF using imageio\n","imageio.mimsave(gif_name, frames, duration=1/desired_frame_rate)\n","\n","# Note: The duration parameter specifies the time each frame is displayed in seconds (1/desired_frame_rate).\n","\n","print(f'GIF saved as {gif_name}')\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["dict_keys(['cur_epoch', 'best_score', 'state_dict', 'optimizer', 'scheduler'])\n"]},{"data":{"text/plain":["ICNet(\n","  (backbone): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (bottom_branch): HighResolutionBranch(\n","    (0): ConvBNAct(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","    (1): ConvBNAct(\n","      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","    (2): ConvBNAct(\n","      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","  )\n","  (ppm): PyramidPoolingModule(\n","    (stage1): Sequential(\n","      (0): AdaptiveAvgPool2d(output_size=1)\n","      (1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (stage2): Sequential(\n","      (0): AdaptiveAvgPool2d(output_size=2)\n","      (1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (stage3): Sequential(\n","      (0): AdaptiveAvgPool2d(output_size=4)\n","      (1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (stage4): Sequential(\n","      (0): AdaptiveAvgPool2d(output_size=6)\n","      (1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (conv): ConvBNAct(\n","      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","  )\n","  (cff42): CascadeFeatureFusionUnit(\n","    (conv1): ConvBNAct(\n","      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): Identity()\n","      )\n","    )\n","    (conv2): ConvBNAct(\n","      (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): Identity()\n","      )\n","    )\n","    (act): Activation(\n","      (activation): ReLU()\n","    )\n","    (classifier): SegHead(\n","      (0): ConvBNAct(\n","        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (cff21): CascadeFeatureFusionUnit(\n","    (conv1): ConvBNAct(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): Identity()\n","      )\n","    )\n","    (conv2): ConvBNAct(\n","      (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): Identity()\n","      )\n","    )\n","    (act): Activation(\n","      (activation): ReLU()\n","    )\n","    (classifier): SegHead(\n","      (0): ConvBNAct(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (seg_head): SegHead(\n","    (0): ConvBNAct(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","    (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","  )\n",")"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Define the ICNet model with the same configuration as during training\n","model_1 = ICNet(num_class=19, n_channel=3, backbone_type='resnet18', act_type='relu', use_aux=True)\n","\n","# Load the checkpoint\n","checkpoint_path = 'C:/Users/avshinde/Downloads/New folder/New folder/save/last.pth'  # Replace with the actual path to your checkpoint file\n","checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # Add map_location argument if needed\n","print(checkpoint.keys())\n","\n","# Load the model state_dict\n","model_1.load_state_dict(checkpoint['state_dict'])\n","\n","model_1=model_1.to(device)\n","\n","# Ensure the model is in evaluation mode\n","model_1.eval()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Parameters: 12881215\n","Non-Zero Parameters: 11430304\n","Zero Parameters: 1450911\n"]}],"source":["total_params = 0\n","non_zero_params = 0\n","zero_params = 0\n","\n","for name, param in model_1.state_dict().items():\n","        total_params += param.numel()\n","        non_zero_params += torch.count_nonzero(param).item()\n","        zero_params += (param.numel() - torch.count_nonzero(param)).item()\n","print(f\"Total Parameters: {total_params}\")\n","print(f\"Non-Zero Parameters: {non_zero_params}\")\n","print(f\"Zero Parameters: {zero_params}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Validating the original model"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","[2023-12-04 09:49] Load model state dict from C:/Users/avshinde/Downloads/New folder/New folder/icnet.pth\n","[2023-12-04 09:49] Resume training from C:/Users/avshinde/Downloads/New folder/New folder/icnet.pth\n","[2023-12-04 09:49] \n","\n","\n","######################### Config Informations #########################\n","dataset: cityscapes\n","num_class: 19\n","model: icnet\n","encoder: None\n","decoder: None\n","loss_type: ohem\n","optimizer_type: adam\n","lr_policy: cos_warmup\n","total_epoch: 10\n","train_bs: 8\n","val_bs: 8\n","train_num: 2968\n","val_num: 500\n","gpu_num: 1\n","num_workers: 8\n","amp_training: False\n","DDP: False\n","kd_training: False\n","synBN: True\n","use_ema: True\n","use_aux: True\n","#######################################################################\n","\n","\n","[2023-12-04 09:49] \n","Train 10 epochs finished!\n","\n","[2023-12-04 09:49] ##################################################\n","Validation for the best checkpoint...\n","Validating:    |: 100%|██████████| 63/63 [02:16<00:00,  2.16s/it] \n","[2023-12-04 09:52] \n","\n","Train 10 epochs finished.\n","\n","Best mIoU is: 0.6965\n","\n","[2023-12-04 09:52] Best validation score is 0.6965434551239014.\n","\n"]},{"name":"stdout","output_type":"stream","text":["tensor(0.6965, device='cuda:0')\n"]}],"source":["from core import SegTrainer\n","from configs import MyConfig, load_parser\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","if __name__ == '__main__':\n","    config = MyConfig()\n","    \n","    config.init_dependent_config()\n","\n","    #config.model = net\n","    # If you want to use command-line arguments, please uncomment the following line\n","    # config = load_parser(config)\n","\n","    trainer = SegTrainer(config)\n","    \n","    if config.is_testing:\n","        trainer.predict(config)\n","    else:    \n","        trainer.run(config)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### mIoU: 69.95"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Predicting on the original model"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","[2023-12-04 09:57] Load model state dict from C:/Users/avshinde/Downloads/New folder/New folder/icnet.pth\n","[2023-12-04 09:57] \n","Start predicting...\n","\n","100%|██████████| 38/38 [09:29<00:00, 14.97s/it]\n"]}],"source":["from core import SegTrainer\n","from configs import MyConfig, load_parser\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","if __name__ == '__main__':\n","    config = MyConfig()\n","    \n","    config.init_dependent_config()\n","\n","    #config.model = net\n","    # If you want to use command-line arguments, please uncomment the following line\n","    # config = load_parser(config)\n","\n","    trainer = SegTrainer(config)\n","    \n","    if config.is_testing:\n","        trainer.predict(config)\n","    else:    \n","        trainer.run(config)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Video Output"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import cv2\n","import os\n","from natsort import natsorted\n","\n","# Directory containing the predicted segmentation images\n","image_folder = 'C:/Users/avshinde/Downloads/New folder/New folder/save/mainz_unpruned/blend'\n","\n","# Output video file name\n","video_name = 'output_video_mainz_unpruned.avi'\n","\n","# Get the list of image files and sort them\n","images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n","images = natsorted(images)\n","\n","# Get image dimensions from the first image\n","img = cv2.imread(os.path.join(image_folder, images[0]))\n","height, width, layers = img.shape\n","\n","# Define the desired frame rate (adjust as needed)\n","desired_frame_rate = 1 # Frames per second\n","\n","# Create a VideoWriter object with the desired frame rate\n","video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'XVID'), desired_frame_rate, (width, height))\n","\n","# Loop through the images and write each frame to the video\n","for image in images:\n","    img_path = os.path.join(image_folder, image)\n","    frame = cv2.imread(img_path)\n","    video.write(frame)\n","\n","# Release the VideoWriter object\n","video.release()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["dict_keys(['cur_epoch', 'best_score', 'state_dict', 'optimizer', 'scheduler'])\n"]}],"source":["# Define the ICNet model with the same configuration as during training\n","net = ICNet(num_class=19, n_channel=3, backbone_type='resnet18', act_type='relu', use_aux=True)\n","\n","# Load the checkpoint\n","checkpoint_path = 'C:/Users/avshinde/Downloads/New folder/New folder/last.pth'  # Replace with the actual path to your checkpoint file\n","checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # Add map_location argument if needed\n","print(checkpoint.keys())"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[2023-12-04 11:08] Load model state dict from C:/Users/avshinde/Downloads/New folder/New folder/last.pth\n","[2023-12-04 11:08] Resume training from C:/Users/avshinde/Downloads/New folder/New folder/last.pth\n","[2023-12-04 11:08] \n","\n","\n","######################### Config Informations #########################\n","dataset: cityscapes\n","num_class: 19\n","model: icnet\n","encoder: None\n","decoder: None\n","loss_type: ohem\n","optimizer_type: adam\n","lr_policy: cos_warmup\n","total_epoch: 10\n","train_bs: 8\n","val_bs: 8\n","train_num: 2968\n","val_num: 500\n","gpu_num: 1\n","num_workers: 8\n","amp_training: False\n","DDP: False\n","kd_training: False\n","synBN: True\n","use_ema: True\n","use_aux: True\n","#######################################################################\n","\n","\n","[2023-12-04 11:08] \n","Train 10 epochs finished!\n","\n","[2023-12-04 11:08] ##################################################\n","Validation for the best checkpoint...\n","Validating:    |: 100%|██████████| 63/63 [02:14<00:00,  2.14s/it] \n","[2023-12-04 11:11] \n","\n","Train 10 epochs finished.\n","\n","Best mIoU is: 0.0356\n","\n","[2023-12-04 11:11] Best validation score is 0.03559388592839241.\n","\n"]},{"name":"stdout","output_type":"stream","text":["tensor(0.0356, device='cuda:0')\n"]}],"source":["from core import SegTrainer\n","from configs import MyConfig, load_parser\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","if __name__ == '__main__':\n","    config = MyConfig()\n","    \n","    config.init_dependent_config()\n","\n","    #config.model = net\n","    # If you want to use command-line arguments, please uncomment the following line\n","    # config = load_parser(config)\n","\n","    trainer = SegTrainer(config)\n","    \n","    if config.is_testing:\n","        trainer.predict(config)\n","    else:    \n","        trainer.run(config)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}}},"nbformat":4,"nbformat_minor":0}
