{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":486,"status":"ok","timestamp":1698443153392,"user":{"displayName":"Amarnath Shinde","userId":"15881715752542230515"},"user_tz":240},"id":"HcwRYzV_yGVD","pycharm":{"is_executing":false}},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from models import BiSeNetv2\n","import torch\n","import numpy as np\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["dict_keys(['cur_epoch', 'best_score', 'state_dict', 'optimizer', 'scheduler'])\n"]},{"data":{"text/plain":["BiSeNetv2(\n","  (detail_branch): DetailBranch(\n","    (0): ConvBNAct(\n","      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","    (1): ConvBNAct(\n","      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","    (2): ConvBNAct(\n","      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","    (3): ConvBNAct(\n","      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","    (4): ConvBNAct(\n","      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","    (5): ConvBNAct(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","    (6): ConvBNAct(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","    (7): ConvBNAct(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","  )\n","  (semantic_branch): SemanticBranch(\n","    (stage1to2): StemBlock(\n","      (conv_init): ConvBNAct(\n","        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (left_branch): Sequential(\n","        (0): ConvBNAct(\n","          (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): Activation(\n","            (activation): ReLU()\n","          )\n","        )\n","        (1): ConvBNAct(\n","          (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): Activation(\n","            (activation): ReLU()\n","          )\n","        )\n","      )\n","      (right_branch): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (conv_last): ConvBNAct(\n","        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","    )\n","    (stage3): Sequential(\n","      (0): GatherExpansionLayer(\n","        (right_branch): Sequential(\n","          (0): DWConvBNAct(\n","            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n","            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","          (1): PWConvBNAct(\n","            (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","        )\n","        (left_branch): Sequential(\n","          (0): ConvBNAct(\n","            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): ReLU()\n","            )\n","          )\n","          (1): DWConvBNAct(\n","            (0): Conv2d(16, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","          (2): DWConvBNAct(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","          (3): PWConvBNAct(\n","            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","        )\n","        (act): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): GatherExpansionLayer(\n","        (left_branch): Sequential(\n","          (0): ConvBNAct(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): ReLU()\n","            )\n","          )\n","          (1): DWConvBNAct(\n","            (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","          (2): PWConvBNAct(\n","            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","        )\n","        (act): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","    )\n","    (stage4): Sequential(\n","      (0): GatherExpansionLayer(\n","        (right_branch): Sequential(\n","          (0): DWConvBNAct(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","          (1): PWConvBNAct(\n","            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","        )\n","        (left_branch): Sequential(\n","          (0): ConvBNAct(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): ReLU()\n","            )\n","          )\n","          (1): DWConvBNAct(\n","            (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","          (2): DWConvBNAct(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","          (3): PWConvBNAct(\n","            (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","        )\n","        (act): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): GatherExpansionLayer(\n","        (left_branch): Sequential(\n","          (0): ConvBNAct(\n","            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): ReLU()\n","            )\n","          )\n","          (1): DWConvBNAct(\n","            (0): Conv2d(64, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","          (2): PWConvBNAct(\n","            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","        )\n","        (act): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","    )\n","    (stage5_1to4): Sequential(\n","      (0): GatherExpansionLayer(\n","        (right_branch): Sequential(\n","          (0): DWConvBNAct(\n","            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","          (1): PWConvBNAct(\n","            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","        )\n","        (left_branch): Sequential(\n","          (0): ConvBNAct(\n","            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): ReLU()\n","            )\n","          )\n","          (1): DWConvBNAct(\n","            (0): Conv2d(64, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","          (2): DWConvBNAct(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","          (3): PWConvBNAct(\n","            (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","        )\n","        (act): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): GatherExpansionLayer(\n","        (left_branch): Sequential(\n","          (0): ConvBNAct(\n","            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): ReLU()\n","            )\n","          )\n","          (1): DWConvBNAct(\n","            (0): Conv2d(128, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n","            (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","          (2): PWConvBNAct(\n","            (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","        )\n","        (act): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (2): GatherExpansionLayer(\n","        (left_branch): Sequential(\n","          (0): ConvBNAct(\n","            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): ReLU()\n","            )\n","          )\n","          (1): DWConvBNAct(\n","            (0): Conv2d(128, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n","            (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","          (2): PWConvBNAct(\n","            (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","        )\n","        (act): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (3): GatherExpansionLayer(\n","        (left_branch): Sequential(\n","          (0): ConvBNAct(\n","            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): ReLU()\n","            )\n","          )\n","          (1): DWConvBNAct(\n","            (0): Conv2d(128, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n","            (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","          (2): PWConvBNAct(\n","            (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): Activation(\n","              (activation): Identity()\n","            )\n","          )\n","        )\n","        (act): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","    )\n","    (stage5_5): ContextEmbeddingBlock(\n","      (pool): Sequential(\n","        (0): AdaptiveAvgPool2d(output_size=1)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (conv_mid): ConvBNAct(\n","        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (conv_last): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (seg_head2): SegHead(\n","      (0): ConvBNAct(\n","        (0): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (seg_head3): SegHead(\n","      (0): ConvBNAct(\n","        (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (seg_head4): SegHead(\n","      (0): ConvBNAct(\n","        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (seg_head5): SegHead(\n","      (0): ConvBNAct(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (bga_layer): BilateralGuidedAggregationLayer(\n","    (detail_high): Sequential(\n","      (0): DWConvBNAct(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (detail_low): Sequential(\n","      (0): DWConvBNAct(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","    )\n","    (semantic_high): Sequential(\n","      (0): ConvBNAct(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): Upsample(scale_factor=4.0, mode='bilinear')\n","      (2): Sigmoid()\n","    )\n","    (semantic_low): Sequential(\n","      (0): DWConvBNAct(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): Activation(\n","          (activation): ReLU()\n","        )\n","      )\n","      (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (2): Sigmoid()\n","    )\n","    (conv_last): ConvBNAct(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","  )\n","  (seg_head): SegHead(\n","    (0): ConvBNAct(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): Activation(\n","        (activation): ReLU()\n","      )\n","    )\n","    (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","  )\n",")"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Define the ICNet model with the same configuration as during training\n","net = BiSeNetv2(num_class=19, n_channel=3, act_type='relu', use_aux=True)\n","\n","# Load the checkpoint\n","checkpoint_path = 'C:/Users/avshinde/Downloads/New folder/New folder/bisenetv2-aux.pth'  # Replace with the actual path to your checkpoint file\n","checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # Add map_location argument if needed\n","print(checkpoint.keys())\n","\n","# Load the model state_dict\n","net.load_state_dict(checkpoint['state_dict'])\n","\n","net=net.to(device)\n","\n","# Ensure the model is in evaluation mode\n","net.eval()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Parameters: 2576409\n","Non-Zero Parameters: 2576409\n","Zero Parameters: 0\n"]}],"source":["total_params = 0\n","non_zero_params = 0\n","zero_params = 0\n","\n","for name, param in net.state_dict().items():\n","        total_params += param.numel()\n","        non_zero_params += torch.count_nonzero(param).item()\n","        zero_params += (param.numel() - torch.count_nonzero(param)).item()\n","print(f\"Total Parameters: {total_params}\")\n","print(f\"Non-Zero Parameters: {non_zero_params}\")\n","print(f\"Zero Parameters: {zero_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"00k3oTlVyGVF"},"source":["### Prune"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5215,"status":"ok","timestamp":1698443199199,"user":{"displayName":"Amarnath Shinde","userId":"15881715752542230515"},"user_tz":240},"id":"4pdiSJHZyGVF","outputId":"7ece561c-5eb2-452a-bcb5-e89a589ef625"},"outputs":[],"source":["from prune import prune_icnet\n","prune_icnet(net, method='std', s=0.25)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# If needed, remove pruning\n","from torch.nn.utils import prune\n","\n","for name, module in net.named_modules():\n","    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n","        prune.remove(module, 'weight')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Parameters: 2576409\n","Non-Zero Parameters: 1951209\n","Zero Parameters: 625200\n"]}],"source":["total_params = 0\n","non_zero_params = 0\n","zero_params = 0\n","\n","for name, param in net.state_dict().items():\n","        total_params += param.numel()\n","        non_zero_params += torch.count_nonzero(param).item()\n","        zero_params += (param.numel() - torch.count_nonzero(param)).item()\n","print(f\"Total Parameters: {total_params}\")\n","print(f\"Non-Zero Parameters: {non_zero_params}\")\n","print(f\"Zero Parameters: {zero_params}\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# # Print the names and values of the parameters\n","# for name, param in net.named_parameters():\n","#     print(f'Parameter name: {name}')\n","#     print(f'Parameter shape: {param.shape}')\n","#     print(f'Parameter data:\\n{param.data}\\n')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Create a new model to store the pruned weights\n","pruned_model = BiSeNetv2(num_class=19, n_channel=3, act_type='relu', use_aux=True)\n","pruned_model.load_state_dict(net.state_dict())"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Save the updated checkpoint\n","updated_checkpoint_path = 'updated_checkpoint_BiSeNetv2.pth'\n","checkpoint['state_dict'] = pruned_model.state_dict()\n","checkpoint['cur_epoch'] = 0\n","checkpoint['best_score'] = 0\n","torch.save(checkpoint, updated_checkpoint_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Fine-tuning pruned weights by re-training"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","[2023-12-04 10:47] Load model state dict from C:/Users/avshinde/Downloads/New folder/New folder/updated_checkpoint_BiSeNetv2.pth\n","[2023-12-04 10:47] Resume training from C:/Users/avshinde/Downloads/New folder/New folder/updated_checkpoint_BiSeNetv2.pth\n","[2023-12-04 10:47] \n","\n","\n","######################### Config Informations #########################\n","dataset: cityscapes\n","num_class: 19\n","model: bisenetv2\n","encoder: None\n","decoder: None\n","loss_type: ohem\n","optimizer_type: adam\n","lr_policy: cos_warmup\n","total_epoch: 10\n","train_bs: 8\n","val_bs: 8\n","train_num: 2968\n","val_num: 500\n","gpu_num: 1\n","num_workers: 8\n","amp_training: False\n","DDP: False\n","kd_training: False\n","synBN: True\n","use_ema: True\n","use_aux: True\n","#######################################################################\n","\n","\n","Epoch:1/10    |Loss:5.916    |: 100%|██████████| 371/371 [06:20<00:00,  1.02s/it]\n","Validating:    |: 100%|██████████| 63/63 [02:10<00:00,  2.08s/it] \n","[2023-12-04 10:55]  Epoch1 mIoU: 0.3224    | best mIoU so far: 0.0000\n","\n"]},{"name":"stdout","output_type":"stream","text":["tensor(0.3224, device='cuda:0')\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:2/10    |Loss:5.53    |: 100%|██████████| 371/371 [06:19<00:00,  1.02s/it] \n","Validating:    |: 100%|██████████| 63/63 [02:03<00:00,  1.97s/it] \n","[2023-12-04 11:04]  Epoch2 mIoU: 0.5080    | best mIoU so far: 0.3224\n","\n"]},{"name":"stdout","output_type":"stream","text":["tensor(0.5080, device='cuda:0')\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:3/10    |Loss:6.679    |:  16%|█▌        | 60/371 [01:47<09:16,  1.79s/it] \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m     trainer\u001b[39m.\u001b[39mpredict(config)\n\u001b[0;32m     21\u001b[0m \u001b[39melse\u001b[39;00m:    \n\u001b[1;32m---> 22\u001b[0m     trainer\u001b[39m.\u001b[39;49mrun(config)\n","File \u001b[1;32mc:\\Users\\avshinde\\Downloads\\New folder\\New folder\\core\\base_trainer.py:85\u001b[0m, in \u001b[0;36mBaseTrainer.run\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mfor\u001b[39;00m cur_epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_epoch, config\u001b[39m.\u001b[39mtotal_epoch):\n\u001b[0;32m     83\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_epoch \u001b[39m=\u001b[39m cur_epoch\n\u001b[1;32m---> 85\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_one_epoch(config)\n\u001b[0;32m     87\u001b[0m     \u001b[39mif\u001b[39;00m cur_epoch \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mbegin_val_epoch \u001b[39mand\u001b[39;00m cur_epoch \u001b[39m%\u001b[39m config\u001b[39m.\u001b[39mval_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     88\u001b[0m         val_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate(config)\n","File \u001b[1;32mc:\\Users\\avshinde\\Downloads\\New folder\\New folder\\core\\seg_trainer.py:87\u001b[0m, in \u001b[0;36mSegTrainer.train_one_epoch\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mupdate()\n\u001b[0;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> 87\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mema_model\u001b[39m.\u001b[39;49mupdate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_itrs)\n\u001b[0;32m     89\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmain_rank:\n\u001b[0;32m     90\u001b[0m     pbar\u001b[39m.\u001b[39mset_description((\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m%\u001b[39m \n\u001b[0;32m     91\u001b[0m                     (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch:\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_epoch\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39mtotal_epoch\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m4\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     92\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLoss:\u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mdetach()\u001b[39m:\u001b[39;00m\u001b[39m4.4g\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m4\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m,)\n\u001b[0;32m     93\u001b[0m                     )\n","File \u001b[1;32mc:\\Users\\avshinde\\Downloads\\New folder\\New folder\\utils\\model_ema.py:38\u001b[0m, in \u001b[0;36mModelEmaV2.update\u001b[1;34m(self, model, cur_itrs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_ema:\n\u001b[0;32m     37\u001b[0m     decay \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mmax\u001b[39m(cur_itrs \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_itrs, \u001b[39m0\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update(de_parallel(model), update_fn\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m e, m: decay \u001b[39m*\u001b[39;49m e \u001b[39m+\u001b[39;49m (\u001b[39m1.\u001b[39;49m \u001b[39m-\u001b[39;49m decay) \u001b[39m*\u001b[39;49m m)\n\u001b[0;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update(de_parallel(model), update_fn\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m e, m: m)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\avshinde\\Downloads\\New folder\\New folder\\utils\\model_ema.py:33\u001b[0m, in \u001b[0;36mModelEmaV2._update\u001b[1;34m(self, model, update_fn)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     model_v \u001b[39m=\u001b[39m model_v\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m---> 33\u001b[0m ema_v\u001b[39m.\u001b[39mcopy_(update_fn(ema_v, model_v))\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from core import SegTrainer\n","from configs import MyConfig, load_parser\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","if __name__ == '__main__':\n","    config = MyConfig()\n","    \n","    config.init_dependent_config()\n","\n","    #config.model = net\n","    # If you want to use command-line arguments, please uncomment the following line\n","    # config = load_parser(config)\n","\n","    trainer = SegTrainer(config)\n","    \n","    if config.is_testing:\n","        trainer.predict(config)\n","    else:    \n","        trainer.run(config)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Original mIoU: 73.73\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Obtained mIoU: 66.18"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Prediction on the pruned weights"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","[2023-12-04 09:27] Load model state dict from C:/Users/avshinde/Downloads/New folder/New folder/updated_checkpoint.pth\n","[2023-12-04 09:27] \n","Start predicting...\n","\n","100%|██████████| 38/38 [09:14<00:00, 14.58s/it]\n"]}],"source":["from core import SegTrainer\n","from configs import MyConfig, load_parser\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","if __name__ == '__main__':\n","    config = MyConfig()\n","    \n","    config.init_dependent_config()\n","\n","    #config.model = net\n","    # If you want to use command-line arguments, please uncomment the following line\n","    # config = load_parser(config)\n","\n","    trainer = SegTrainer(config)\n","    \n","    if config.is_testing:\n","        trainer.predict(config)\n","    else:    \n","        trainer.run(config)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Video Output"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import cv2\n","import os\n","from natsort import natsorted\n","\n","# Directory containing the predicted segmentation images\n","image_folder = 'C:/Users/avshinde/Downloads/New folder/New folder/save'\n","\n","# Output video file name\n","video_name = 'output_video_mainz.avi'\n","\n","# Get the list of image files and sort them\n","images = [img for img in os.listdir(image_folder) if img.endswith(\"blend.png\")]\n","images = natsorted(images)\n","\n","# Get image dimensions from the first image\n","img = cv2.imread(os.path.join(image_folder, images[0]))\n","height, width, layers = img.shape\n","\n","# Define the desired frame rate (adjust as needed)\n","desired_frame_rate = 1 # Frames per second\n","\n","# Create a VideoWriter object with the desired frame rate\n","video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'XVID'), desired_frame_rate, (width, height))\n","\n","# Loop through the images and write each frame to the video\n","for image in images:\n","    img_path = os.path.join(image_folder, image)\n","    frame = cv2.imread(img_path)\n","    video.write(frame)\n","\n","# Release the VideoWriter object\n","video.release()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["GIF saved as output_video_mainz.gif\n"]}],"source":["import cv2\n","import os\n","from natsort import natsorted\n","import imageio\n","\n","# Directory containing the predicted segmentation images\n","image_folder = 'C:/Users/avshinde/Downloads/New folder/New folder/save'\n","\n","# Output GIF file name\n","gif_name = 'output_video_mainz.gif'\n","\n","# Get the list of image files and sort them\n","images = [img for img in os.listdir(image_folder) if img.endswith(\"blend.png\")]\n","images = natsorted(images)\n","\n","# Get image dimensions from the first image\n","img = cv2.imread(os.path.join(image_folder, images[0]))\n","height, width, layers = img.shape\n","\n","# Define the desired frame rate (adjust as needed)\n","desired_frame_rate = 0.7 # Frames per second\n","\n","# Create a list to store frames\n","frames = []\n","\n","# Loop through the images and append each frame to the list\n","for image in images:\n","    img_path = os.path.join(image_folder, image)\n","    frame = cv2.imread(img_path)\n","    # Ensure that the color channels are in the correct order (BGR)\n","    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    frames.append(frame)\n","\n","# Save the frames as a GIF using imageio\n","imageio.mimsave(gif_name, frames, duration=1/desired_frame_rate)\n","\n","# Note: The duration parameter specifies the time each frame is displayed in seconds (1/desired_frame_rate).\n","\n","print(f'GIF saved as {gif_name}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Validating the original model"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","[2023-12-04 10:27] Load model state dict from C:/Users/avshinde/Downloads/New folder/New folder/bisenetv2-aux.pth\n","[2023-12-04 10:27] Resume training from C:/Users/avshinde/Downloads/New folder/New folder/bisenetv2-aux.pth\n","[2023-12-04 10:27] \n","\n","\n","######################### Config Informations #########################\n","dataset: cityscapes\n","num_class: 19\n","model: bisenetv2\n","encoder: None\n","decoder: None\n","loss_type: ohem\n","optimizer_type: adam\n","lr_policy: cos_warmup\n","total_epoch: 10\n","train_bs: 8\n","val_bs: 8\n","train_num: 2968\n","val_num: 500\n","gpu_num: 1\n","num_workers: 8\n","amp_training: False\n","DDP: False\n","kd_training: False\n","synBN: True\n","use_ema: True\n","use_aux: True\n","#######################################################################\n","\n","\n","[2023-12-04 10:27] \n","Train 10 epochs finished!\n","\n","[2023-12-04 10:27] ##################################################\n","Validation for the best checkpoint...\n","Validating:    |: 100%|██████████| 63/63 [02:03<00:00,  1.96s/it] \n","[2023-12-04 10:29] \n","\n","Train 10 epochs finished.\n","\n","Best mIoU is: 0.7373\n","\n","[2023-12-04 10:29] Best validation score is 0.7373115420341492.\n","\n"]},{"name":"stdout","output_type":"stream","text":["tensor(0.7373, device='cuda:0')\n"]}],"source":["from core import SegTrainer\n","from configs import MyConfig, load_parser\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","if __name__ == '__main__':\n","    config = MyConfig()\n","    \n","    config.init_dependent_config()\n","\n","    #config.model = net\n","    # If you want to use command-line arguments, please uncomment the following line\n","    # config = load_parser(config)\n","\n","    trainer = SegTrainer(config)\n","    \n","    if config.is_testing:\n","        trainer.predict(config)\n","    else:    \n","        trainer.run(config)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### mIoU: 73.73"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Predicting on the original model"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\avshinde\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","[2023-12-04 10:32] Load model state dict from C:/Users/avshinde/Downloads/New folder/New folder/bisenetv2-aux.pth\n","[2023-12-04 10:32] \n","Start predicting...\n","\n","100%|██████████| 38/38 [09:09<00:00, 14.45s/it]\n"]}],"source":["from core import SegTrainer\n","from configs import MyConfig, load_parser\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","if __name__ == '__main__':\n","    config = MyConfig()\n","    \n","    config.init_dependent_config()\n","\n","    #config.model = net\n","    # If you want to use command-line arguments, please uncomment the following line\n","    # config = load_parser(config)\n","\n","    trainer = SegTrainer(config)\n","    \n","    if config.is_testing:\n","        trainer.predict(config)\n","    else:    \n","        trainer.run(config)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Video Output"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import cv2\n","import os\n","from natsort import natsorted\n","\n","# Directory containing the predicted segmentation images\n","image_folder = 'C:/Users/avshinde/Downloads/New folder/New folder/save/mainz_unpruned_bisenetv2/blend'\n","\n","# Output video file name\n","video_name = 'output_video_mainz_unpruned.avi'\n","\n","# Get the list of image files and sort them\n","images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n","images = natsorted(images)\n","\n","# Get image dimensions from the first image\n","img = cv2.imread(os.path.join(image_folder, images[0]))\n","height, width, layers = img.shape\n","\n","# Define the desired frame rate (adjust as needed)\n","desired_frame_rate = 1 # Frames per second\n","\n","# Create a VideoWriter object with the desired frame rate\n","video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'XVID'), desired_frame_rate, (width, height))\n","\n","# Loop through the images and write each frame to the video\n","for image in images:\n","    img_path = os.path.join(image_folder, image)\n","    frame = cv2.imread(img_path)\n","    video.write(frame)\n","\n","# Release the VideoWriter object\n","video.release()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}}},"nbformat":4,"nbformat_minor":0}
